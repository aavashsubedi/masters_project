{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch_geometric as pyg\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ska_data_file = \"/workspaces/masters_project/data/ska/new_raw_data.txt\"\n",
    "#load the file into a numpy array\n",
    "df = pd.read_csv(ska_data_file, sep=\" \", header=None)\n",
    "#convert the pandas dataframe to a numpy array\n",
    "data = df.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a square matrix corresponding to the number of nodes and fill it with the euclidean distance between each point. \n",
    "#the last two element of each row is the x and y coordinate of the point\n",
    "n = len(data)\n",
    "dist_matrix = np.zeros((n,n))\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        x_i, y_i = data[i][-2], data[i][-1]\n",
    "        x_j, y_j = data[j][-2], data[j][-1]\n",
    "        euclidean_distance = (x_i - x_j)**2 + (y_i - y_j)**2\n",
    "        euclidean_distance = euclidean_distance**0.5\n",
    "        dist_matrix[i][j] = euclidean_distance\n",
    "dist_matrix = torch.tensor(dist_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[3], edge_index=[2, 3], pos=[3, 2], edge_attr=[3, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = torch.load(\"/workspaces/masters_project/data/graph_dataset.pt\")\n",
    "graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0328, 0.0267,  ..., 0.5790, 0.6921, 0.8430],\n",
       "        [0.0328, 0.0000, 0.0586,  ..., 0.5594, 0.6797, 0.8393],\n",
       "        [0.0267, 0.0586, 0.0000,  ..., 0.5878, 0.6942, 0.8376],\n",
       "        ...,\n",
       "        [0.5790, 0.5594, 0.5878,  ..., 0.0000, 0.1968, 0.4525],\n",
       "        [0.6921, 0.6797, 0.6942,  ..., 0.1968, 0.0000, 0.2595],\n",
       "        [0.8430, 0.8393, 0.8376,  ..., 0.4525, 0.2595, 0.0000]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering, spectral_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means(data, num_clusters, max_iters=100):\n",
    "    \"\"\"For data we'll use eigenvalues of the Laplacian of a graph\"\"\"\n",
    "    centroids = data[:num_clusters, :]\n",
    "    for _ in range(max_iters):\n",
    "        distances = torch.cdist(data, centroids, p=2)\n",
    "        cluster_assignments = torch.argmin(distances, dim=1)\n",
    "        new_centroids = torch.stack([data[cluster_assignments == i].mean(0) for i in range(num_clusters)])\n",
    "        if torch.equal(new_centroids, centroids):\n",
    "            break\n",
    "        centroids = new_centroids\n",
    "        \n",
    "    return centroids, cluster_assignments\n",
    "def spectral_clustering_labeebs(adjacency_matrix, num_clusters=2):\n",
    "    # Laplacian:\n",
    "    degree_matrix = torch.diag(torch.sum(adjacency_matrix, dim=1))\n",
    "    laplacian_matrix = degree_matrix - adjacency_matrix\n",
    "\n",
    "    # Eigenvalue Decomposition\n",
    "    eigenvalues, eigenvectors = torch.linalg.eigh(laplacian_matrix)\n",
    "    eigenvectors = eigenvectors[:, 1:num_clusters+1]  # Use the first num_clusters eigenvectors\n",
    "    eigenvectors = F.normalize(eigenvectors, p=2, dim=1)\n",
    "\n",
    "    # K-Means for clustering\n",
    "    centroids, cluster_assignments = k_means(eigenvectors, num_clusters)\n",
    "\n",
    "    return cluster_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_edges(data, node_id):\n",
    "    \"\"\"\n",
    "    Extracts the edges from a graph and returns a list of edges\n",
    "    \"\"\"\n",
    "    #get the edges\n",
    "    subset = torch.tensor(node_id)\n",
    "#    \n",
    "    edge_index, edge_attr  = pyg.utils.subgraph(subset=torch.tensor(node_id),\n",
    "                                                 edge_index=data.edge_index,\n",
    "                                                   edge_attr=data.edge_attr)\n",
    "    subg_data = data.x[torch.tensor(node_id)]\n",
    "    subgraph = pyg.data.Data(x = subg_data , edge_index=edge_index, edge_attr=edge_attr)\n",
    "\n",
    "    return subgraph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cluster_classifcation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cluster_1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(\u001b[43mcluster_classifcation\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      2\u001b[0m cluster_2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(cluster_classifcation \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cluster_classifcation' is not defined"
     ]
    }
   ],
   "source": [
    "cluster_1 = np.where(cluster_classifcation == 0)[0]\n",
    "cluster_2 = np.where(cluster_classifcation == 1)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0,   2,   3,   4,   5,   7,  10,  11,  13,  14,  15,  16,  18,  19,\n",
      "         20,  21,  22,  25,  26,  27,  29,  30,  32,  35,  36,  37,  39,  41,\n",
      "         42,  43,  44,  46,  48,  52,  53,  60,  64,  65,  66,  67,  69,  70,\n",
      "         72,  73,  74,  75,  76,  77,  80,  81,  83,  84,  85,  86,  87,  89,\n",
      "         90,  92,  93,  95,  96,  98,  99, 100, 101, 102, 104, 105, 107, 108,\n",
      "        109, 112, 113, 114, 115, 116, 117, 119, 120, 122, 124, 125, 129, 130,\n",
      "        133, 134, 136, 138, 139, 144, 145, 152, 155, 159, 163, 168, 173, 178,\n",
      "        180, 183, 187, 190, 191])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for dimension 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#nodes in cluster 2\u001b[39;00m\n\u001b[1;32m      8\u001b[0m cluster_2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(cluster_classifcation \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 11\u001b[0m subgraph_1 \u001b[38;5;241m=\u001b[39m \u001b[43mextract_edges\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcluster_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m subgraph_2 \u001b[38;5;241m=\u001b[39m extract_edges(graph, cluster_2)\n\u001b[1;32m     13\u001b[0m edges_length_1 \u001b[38;5;241m=\u001b[39m subgraph_1\u001b[38;5;241m.\u001b[39medge_attr\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "Cell \u001b[0;32mIn[21], line 9\u001b[0m, in \u001b[0;36mextract_edges\u001b[0;34m(data, node_id)\u001b[0m\n\u001b[1;32m      6\u001b[0m subset \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(node_id)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(subset)\n\u001b[0;32m----> 9\u001b[0m edge_index, edge_attr  \u001b[38;5;241m=\u001b[39m \u001b[43mpyg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubgraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m subg_data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mx[torch\u001b[38;5;241m.\u001b[39mtensor(node_id)]\n\u001b[1;32m     12\u001b[0m subgraph \u001b[38;5;241m=\u001b[39m pyg\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mData(x \u001b[38;5;241m=\u001b[39m subg_data , edge_index\u001b[38;5;241m=\u001b[39medge_index, edge_attr\u001b[38;5;241m=\u001b[39medge_attr)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/torch_geometric/utils/subgraph.py:92\u001b[0m, in \u001b[0;36msubgraph\u001b[0;34m(subset, edge_index, edge_attr, relabel_nodes, num_nodes, return_edge_mask)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m subset\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbool:\n\u001b[1;32m     91\u001b[0m     num_nodes \u001b[38;5;241m=\u001b[39m maybe_num_nodes(edge_index, num_nodes)\n\u001b[0;32m---> 92\u001b[0m     node_mask \u001b[38;5;241m=\u001b[39m \u001b[43mindex_to_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     94\u001b[0m     num_nodes \u001b[38;5;241m=\u001b[39m subset\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/torch_geometric/utils/mask.py:53\u001b[0m, in \u001b[0;36mindex_to_mask\u001b[0;34m(index, size)\u001b[0m\n\u001b[1;32m     51\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(index\u001b[38;5;241m.\u001b[39mmax()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m size\n\u001b[1;32m     52\u001b[0m mask \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39mnew_zeros(size, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbool)\n\u001b[0;32m---> 53\u001b[0m \u001b[43mmask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mask\n",
      "\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for dimension 0 with size 3"
     ]
    }
   ],
   "source": [
    "# cluster_classifcation = spectral_clustering(dist_matrix,\n",
    "#                                              n_clusters=2, assign_labels=\"cluster_qr\", random_state=0)\n",
    "cluster_classifcation = spectral_clustering_labeebs(dist_matrix, num_clusters=2)\n",
    "\n",
    "#nodes in cluster 1\n",
    "cluster_1 = np.where(cluster_classifcation == 0)[0]\n",
    "#nodes in cluster 2\n",
    "cluster_2 = np.where(cluster_classifcation == 1)[0]\n",
    "\n",
    "\n",
    "subgraph_1 = extract_edges(graph, cluster_1)\n",
    "subgraph_2 = extract_edges(graph, cluster_2)\n",
    "edges_length_1 = subgraph_1.edge_attr.numpy()\n",
    "edges_length_2 = subgraph_2.edge_attr.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "        1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "        0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_classifcation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((103,), (94,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_1.shape, cluster_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'edges_length_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#plot the two edges\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m hist1, bins1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhistogram(\u001b[43medges_length_1\u001b[49m, bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, density\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m hist2, bins2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhistogram(edges_length_2, bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, density\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Normalize the histograms\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'edges_length_1' is not defined"
     ]
    }
   ],
   "source": [
    "#plot the two edges\n",
    "hist1, bins1 = np.histogram(edges_length_1, bins=20, density=True)\n",
    "hist2, bins2 = np.histogram(edges_length_2, bins=20, density=True)\n",
    "\n",
    "# Normalize the histograms\n",
    "hist1 /= hist1.sum()\n",
    "hist2 /= hist2.sum()\n",
    "\n",
    "# Calculate the bin centers\n",
    "bin_centers1 = (bins1[:-1] + bins1[1:]) / 2\n",
    "bin_centers2 = (bins2[:-1] + bins2[1:]) / 2\n",
    "\n",
    "# Plot the normalized histograms\n",
    "plt.bar(bin_centers1, hist1, width=(bin_centers1[1] - bin_centers1[0]), alpha=0.5, label='Dataset 1')\n",
    "plt.bar(bin_centers2, hist2, width=(bin_centers2[1] - bin_centers2[0]), alpha=0.5, label='Dataset 2')\n",
    "plt.xlabel(\"Edge Length\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.legend(loc='upper right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#compute the KL divergence\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m kl_divergence \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\u001b[43mhist1\u001b[49m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(hist1 \u001b[38;5;241m/\u001b[39m hist2))\n\u001b[1;32m      3\u001b[0m kl_divergence\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hist1' is not defined"
     ]
    }
   ],
   "source": [
    "#compute the KL divergence\n",
    "kl_divergence = np.sum(hist1 * np.log(hist1 / hist2))\n",
    "kl_divergence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a ML model for it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing: Use the adjancey matrix + the x values of the graph to come up with something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_adj(x_val, adjaceny_matrix):\n",
    "    \"\"\"\n",
    "    x_val goes from [0, 512] for the 512 nodes in the graph\n",
    "    adjaceny_matrix is the adjacency matrix of the graph\n",
    "    we want to multiply each element of ajacney matrix by x_val. \n",
    "    for two of them we do x_val_i * x_val_j * adjaceny_matrix[i][j]\n",
    "    \"\"\"\n",
    "    #get the number of nodes\n",
    "    n = len(adjaceny_matrix)\n",
    "    #create a matrix of zeros\n",
    "    new_matrix = np.zeros((n,n))\n",
    "    #loop through the matrix and multiply each element by x_val\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            new_matrix[i][j] = x_val[i] * x_val[j] * adjaceny_matrix[i][j]\n",
    "    return new_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can pass this as input to the Spectral Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiply_adj_matrix = multiply_adj(graph.x, dist_matrix.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197, 197)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply_adj_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now get clustering for this matrix\n",
    "cluster_classification = spectral_clustering_labeebs(torch.tensor(multiply_adj_matrix), num_clusters=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralClusteringClass(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, num_clusters=2,\n",
    "                dist_matrix=dist_matrix):\n",
    "        ctx.num_clusters = 2\n",
    "        multiply_adj_matrix = multiply_adj(input, dist_matrix.numpy())\n",
    "        return spectral_clustering_labeebs(multiply_adj_matrix, num_clusters=2)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "  \n",
    "        return grad_output, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradApproxGraph(torch.autograd.Function):\n",
    "    def __init__(self, model, input_data, lambda_val=20,\n",
    "                 example_input=None):\n",
    "        \"\"\"\n",
    "        input_data here is a graph with the correct edges. and setup.\n",
    "        Doing this will let us pass the model through the graph itself.\n",
    "        \"\"\"\n",
    "        self.input_data = input_data # graph\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "        self.prev_input = example_input\n",
    "        self.curr_output = None\n",
    "        self.lambda_val = lambda_val\n",
    "        self.model = model\n",
    "        \n",
    "    @staticmethod\n",
    "    def forward(ctx, combinatorial_solver_output, x, graph_obj):\n",
    "        \"\"\"\n",
    "        Combinatorial solver output is [num_nodes, 1]\n",
    "        gnn_output is [num_nodes, 1]\n",
    "\n",
    "        \"\"\"\n",
    "        ctx.save_for_backward(combinatorial_solver_output, x) \n",
    "        ctx.graph = graph_obj # save_for_backward doesn't work for non-tensors\n",
    "        \n",
    "        return combinatorial_solver_output\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        lambda_val = 20\n",
    "        combinatorial_solver_output, x = ctx.saved_tensors\n",
    "        graph = ctx.graph\n",
    "\n",
    "        perturbed_gnn_weights = x + torch.multiply(lambda_val, grad_input)\n",
    "        perturbed_gnn_output = SpectralClusteringClass.apply(perturbed_gnn_weights, graph)\n",
    "        new_grads = - (1 / lambda_val) * (combinatorial_solver_output - perturbed_gnn_output)\n",
    "        import copy\n",
    "        new_grads_2 = copy.deepcopy(new_grads)\n",
    "        new_grads_2.requires_grad_(True).unsqueeze_(-1)\n",
    "        \n",
    "        return new_grads, new_grads_2, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "class WarCraftModel(torch.nn.Module):\n",
    "    def __init__(self, cfg, ):\n",
    "        super(WarCraftModel, self).__init__()\n",
    "        self.cfg = cfg\n",
    "        self.conv1 = GCNConv(1, 32)\n",
    "        self.conv2 = GCNConv(32, 32)\n",
    "        self.conv3 = GCNConv(32, 1)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(32)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(32)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(32)\n",
    "\n",
    "        self.combinatorial_solver = SpectralClusteringClass.apply\n",
    "        self.grad_approx = GradApproxGraph.apply\n",
    "\n",
    "    def forward(self, data, embedding_output=False,\n",
    "                additional_feat=True):\n",
    "        x, edge_index, edge_attr = data.mean_color, data.edge_index, data.edge_attr\n",
    "        edge_index = edge_index.to(torch.long).to(device)\n",
    "        edge_attr = edge_attr.to(torch.float).to(device)\n",
    "        x = x.to(torch.float).to(device)\n",
    "        #import pdb; pdb.set_trace()\n",
    "        x = self.conv1(x, edge_index, edge_attr.float())\n",
    "        x = self.bn1(x)\n",
    "        x = torch.nn.ReLU()(x)\n",
    "        x = self.conv2(x, edge_index, edge_attr.float())\n",
    "        x = self.bn2(x)\n",
    "        x = torch.nn.ReLU()(x)\n",
    "        x = self.conv3(x, edge_index, edge_attr.float())\n",
    "        #x = global_max_pool(x, data.batch) # This might not work (issues with shape?)\n",
    "        #gradients have issues here. \n",
    "        #x.shape here is [123, 1]. so maybe we unsqueeze here\n",
    "\n",
    "        combinatorial_solver_output = self.combinatorial_solver(x, data)\n",
    "        x = self.grad_approx(combinatorial_solver_output, x, data)\n",
    "\n",
    "        return x \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SpectralClusteringClass' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mWarCraftModel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "Cell \u001b[0;32mIn[30], line 14\u001b[0m, in \u001b[0;36mWarCraftModel.__init__\u001b[0;34m(self, cfg)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mBatchNorm1d(\u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn3 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mBatchNorm1d(\u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcombinatorial_solver \u001b[38;5;241m=\u001b[39m \u001b[43mSpectralClusteringClass\u001b[49m\u001b[38;5;241m.\u001b[39mapply\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad_approx \u001b[38;5;241m=\u001b[39m GradApproxGraph\u001b[38;5;241m.\u001b[39mapply\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SpectralClusteringClass' is not defined"
     ]
    }
   ],
   "source": [
    "model = WarCraftModel(None)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets get some Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss will be the \"clustering\" approximator and then we use this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for dimension 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#nodes in cluster 2\u001b[39;00m\n\u001b[1;32m      3\u001b[0m cluster_2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(cluster_classifcation \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m subgraph_1 \u001b[38;5;241m=\u001b[39m \u001b[43mextract_edges\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcluster_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m subgraph_2 \u001b[38;5;241m=\u001b[39m extract_edges(graph, cluster_2)\n\u001b[1;32m      8\u001b[0m edges_length_1 \u001b[38;5;241m=\u001b[39m subgraph_1\u001b[38;5;241m.\u001b[39medge_attr\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "Cell \u001b[0;32mIn[27], line 8\u001b[0m, in \u001b[0;36mextract_edges\u001b[0;34m(data, node_id)\u001b[0m\n\u001b[1;32m      6\u001b[0m     subset \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(node_id)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#    \u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     edge_index, edge_attr  \u001b[38;5;241m=\u001b[39m \u001b[43mpyg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubgraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     subg_data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mx[torch\u001b[38;5;241m.\u001b[39mtensor(node_id)]\n\u001b[1;32m     12\u001b[0m     subgraph \u001b[38;5;241m=\u001b[39m pyg\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mData(x \u001b[38;5;241m=\u001b[39m subg_data , edge_index\u001b[38;5;241m=\u001b[39medge_index, edge_attr\u001b[38;5;241m=\u001b[39medge_attr)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/torch_geometric/utils/subgraph.py:92\u001b[0m, in \u001b[0;36msubgraph\u001b[0;34m(subset, edge_index, edge_attr, relabel_nodes, num_nodes, return_edge_mask)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m subset\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbool:\n\u001b[1;32m     91\u001b[0m     num_nodes \u001b[38;5;241m=\u001b[39m maybe_num_nodes(edge_index, num_nodes)\n\u001b[0;32m---> 92\u001b[0m     node_mask \u001b[38;5;241m=\u001b[39m \u001b[43mindex_to_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     94\u001b[0m     num_nodes \u001b[38;5;241m=\u001b[39m subset\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/torch_geometric/utils/mask.py:53\u001b[0m, in \u001b[0;36mindex_to_mask\u001b[0;34m(index, size)\u001b[0m\n\u001b[1;32m     51\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(index\u001b[38;5;241m.\u001b[39mmax()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m size\n\u001b[1;32m     52\u001b[0m mask \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39mnew_zeros(size, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbool)\n\u001b[0;32m---> 53\u001b[0m \u001b[43mmask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mask\n",
      "\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for dimension 0 with size 3"
     ]
    }
   ],
   "source": [
    "cluster_1 = np.where(cluster_classifcation == 0)[0]\n",
    "#nodes in cluster 2\n",
    "cluster_2 = np.where(cluster_classifcation == 1)[0]\n",
    "\n",
    "\n",
    "subgraph_1 = extract_edges(graph, cluster_1)\n",
    "subgraph_2 = extract_edges(graph, cluster_2)\n",
    "edges_length_1 = subgraph_1.edge_attr.numpy()\n",
    "edges_length_2 = subgraph_2.edge_attr.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4371, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_length_1.shape  #these two are both generated by the same graph\n",
    "edges_length_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem now is to get a differentiable form of getting classification to meaningful edges.\n",
    "shape of classifcation = [n, 1] \n",
    "then we get a mask of \"edges\".\n",
    "then we get a histogram of edges etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_1 = torch.histogram(torch.tensor(edges_length_1), bins=20, density=True)\n",
    "dist_2 = torch.histogram(torch.tensor(edges_length_2), bins=20, density=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.return_types.histogram(\n",
       " hist=tensor([1.1713e+01, 1.4410e+00, 6.5873e-01, 3.8769e-01, 8.1998e-01, 3.8083e-01,\n",
       "         4.3915e-01, 4.7689e-01, 3.3966e-01, 1.8870e-01, 4.3916e-01, 5.1463e-02,\n",
       "         4.8033e-02, 2.8820e-01, 2.0585e-02, 6.8618e-02, 2.4702e-01, 3.4309e-03,\n",
       "         3.4309e-03, 6.8618e-03]),\n",
       " bin_edges=tensor([2.7662e-04, 5.5763e-02, 1.1125e-01, 1.6674e-01, 2.2222e-01, 2.7771e-01,\n",
       "         3.3319e-01, 3.8868e-01, 4.4417e-01, 4.9965e-01, 5.5514e-01, 6.1062e-01,\n",
       "         6.6611e-01, 7.2160e-01, 7.7708e-01, 8.3257e-01, 8.8806e-01, 9.4354e-01,\n",
       "         9.9903e-01, 1.0545e+00, 1.1100e+00])),\n",
       " torch.return_types.histogram(\n",
       " hist=tensor([8.9694e+00, 1.2111e+00, 9.4333e-01, 3.1756e-01, 2.8020e-01, 2.5840e-01,\n",
       "         2.6774e-01, 2.7086e-01, 2.3350e-01, 2.9265e-01, 9.9626e-02, 1.9925e-01,\n",
       "         2.3661e-01, 1.2453e-02, 3.1133e-03, 3.1133e-03, 3.1133e-03, 0.0000e+00,\n",
       "         3.1133e-03, 3.1133e-03]),\n",
       " bin_edges=tensor([2.7752e-04, 7.3762e-02, 1.4725e-01, 2.2073e-01, 2.9422e-01, 3.6770e-01,\n",
       "         4.4119e-01, 5.1467e-01, 5.8816e-01, 6.6164e-01, 7.3513e-01, 8.0861e-01,\n",
       "         8.8210e-01, 9.5558e-01, 1.0291e+00, 1.1026e+00, 1.1760e+00, 1.2495e+00,\n",
       "         1.3230e+00, 1.3965e+00, 1.4700e+00])))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the KL divergence of a histogram\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
